{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0bedbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca3c0c8",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation (Correct Train/Validation Split and Stratification Fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5306239b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Dropping 4 rare classes for stratification: ['    mostly-true', '    true', '    pants-fire', '    half-true']\n"
     ]
    }
   ],
   "source": [
    "col_names = [\n",
    "    \"ID\", \"Label\", \"Statement\", \"Subject(s)\", \"Speaker\", \n",
    "    \"Speaker Job Title\", \"State Info\", \"Party Affiliation\", \"Barely True Counts\",\n",
    "    \"False Counts\", \"Half True Counts\", \"Mostly True Counts\", \"Pants on Fire Counts\", \n",
    "    \"Context\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    train_df = pd.read_csv(\"./Data/train.tsv\", sep=\"\\t\", header=None, names=col_names)\n",
    "    valid_df = pd.read_csv(\"./Data/valid.tsv\", sep=\"\\t\", header=None, names=col_names)\n",
    "    # We still load test_df, but it is not used in this notebook for comparison.\n",
    "    # test_df = pd.read_csv(\"test.tsv\", sep=\"\\t\", header=None, names=col_names)\n",
    "except FileNotFoundError:\n",
    "    print(\"Using Dummy Data: Ensure train.tsv, valid.tsv, and test.tsv are in the working directory.\")\n",
    "    # Creating robust dummy dataframes to prevent crash and test logic\n",
    "    data_train = {'Statement': ['The sun is green', 'Water is wet', 'The moon is cheese', 'Lies are bad'] * 100, 'Label': ['false', 'true', 'pants-fire', 'mostly-true'] * 100}\n",
    "    data_valid = {'Statement': ['The sky is blue', 'Birds fly south', 'Cars drive fast', 'Trees are tall'] * 20, 'Label': ['true', 'mostly-true', 'half-true', 'barely-true'] * 20}\n",
    "    data_test = {'Statement': ['Test statement A', 'Test statement B'], 'Label': ['false', 'true']}\n",
    "    train_df = pd.DataFrame(data_train)\n",
    "    valid_df = pd.DataFrame(data_valid)\n",
    "    test_df = pd.DataFrame(data_test)\n",
    "    # Add necessary columns for robust concatenation, fill with 0 or empty string\n",
    "    for df in [train_df, valid_df, test_df]:\n",
    "        for col in col_names:\n",
    "            if col not in df.columns:\n",
    "                df[col] = '' if df[col].dtype == object else 0\n",
    "        df.columns = col_names[:len(df.columns)]\n",
    "\n",
    "# 1. Combine training and validation data into a single development set\n",
    "dev_full = pd.concat([train_df, valid_df], ignore_index=True)[['Statement', 'Label']]\n",
    "\n",
    "# 2. Prepare for splitting: identify and remove classes with only one instance to fix stratification error\n",
    "y_dev = dev_full['Label']\n",
    "class_counts = y_dev.value_counts()\n",
    "rare_classes = class_counts[class_counts < 2].index.tolist()\n",
    "\n",
    "if rare_classes:\n",
    "    print(f\"Warning: Dropping {len(rare_classes)} rare classes for stratification: {rare_classes}\")\n",
    "    dev_full_filtered = dev_full[~dev_full['Label'].isin(rare_classes)]\n",
    "else:\n",
    "    dev_full_filtered = dev_full\n",
    "\n",
    "# 3. Split the development set into training and validation sets for comparison\n",
    "X_dev = dev_full_filtered['Statement'].fillna('')\n",
    "y_dev_filtered = dev_full_filtered['Label']\n",
    "\n",
    "# 80% for training, 20% for validation/comparison\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_dev, y_dev_filtered, test_size=0.2, random_state=42, stratify=y_dev_filtered\n",
    ")\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_val_encoded = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Preprocessing Implementations (BAT, Lemmatization, Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def basic_text_cleaning(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "def apply_lemmatization(tokens):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in tokens])\n",
    "\n",
    "def apply_stemming(tokens):\n",
    "    return ' '.join([stemmer.stem(word) for word in tokens])\n",
    "\n",
    "def preprocess_ml(text, method='lemma'):\n",
    "    tokens = basic_text_cleaning(text)\n",
    "    if method == 'stem':\n",
    "        return apply_stemming(tokens)\n",
    "    return apply_lemmatization(tokens)\n",
    "\n",
    "X_train_lem = X_train.apply(lambda x: preprocess_ml(x, 'lemma'))\n",
    "X_val_lem = X_val.apply(lambda x: preprocess_ml(x, 'lemma'))\n",
    "\n",
    "X_train_stem = X_train.apply(lambda x: preprocess_ml(x, 'stem'))\n",
    "X_val_stem = X_val.apply(lambda x: preprocess_ml(x, 'stem'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classical ML Models (Lemmatized Text + TF-IDF Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\Documents\\Projects\\Capstone-Project-ML2\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\LENOVO\\Documents\\Projects\\Capstone-Project-ML2\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.20      0.15      0.17       378\n",
      "       false       0.26      0.33      0.29       452\n",
      "   half-true       0.24      0.32      0.27       472\n",
      " mostly-true       0.27      0.31      0.29       442\n",
      "  pants-fire       0.37      0.07      0.12       191\n",
      "        true       0.24      0.19      0.21       369\n",
      "\n",
      "    accuracy                           0.25      2304\n",
      "   macro avg       0.26      0.23      0.22      2304\n",
      "weighted avg       0.25      0.25      0.24      2304\n",
      "\n",
      "--- Naive Bayes ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.19      0.12      0.15       378\n",
      "       false       0.25      0.31      0.28       452\n",
      "   half-true       0.24      0.39      0.29       472\n",
      " mostly-true       0.24      0.31      0.27       442\n",
      "  pants-fire       0.40      0.01      0.02       191\n",
      "        true       0.28      0.11      0.16       369\n",
      "\n",
      "    accuracy                           0.24      2304\n",
      "   macro avg       0.27      0.21      0.20      2304\n",
      "weighted avg       0.25      0.24      0.22      2304\n",
      "\n",
      "--- Linear SVM ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.17      0.16      0.17       378\n",
      "       false       0.25      0.27      0.26       452\n",
      "   half-true       0.26      0.28      0.27       472\n",
      " mostly-true       0.24      0.24      0.24       442\n",
      "  pants-fire       0.23      0.18      0.20       191\n",
      "        true       0.25      0.25      0.25       369\n",
      "\n",
      "    accuracy                           0.24      2304\n",
      "   macro avg       0.23      0.23      0.23      2304\n",
      "weighted avg       0.24      0.24      0.24      2304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_ml = {}\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(solver='liblinear', multi_class='auto', random_state=42, max_iter=2000),\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Linear SVM': LinearSVC(random_state=42, max_iter=2000)\n",
    "}\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(ngram_range=(1, 2), max_features=5000)),\n",
    "        ('clf', classifier)\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train_lem, y_train_encoded)\n",
    "    y_pred = pipeline.predict(X_val_lem)\n",
    "    \n",
    "    results_ml[name] = {\n",
    "        'Accuracy': accuracy_score(y_val_encoded, y_pred),\n",
    "        'Precision': precision_score(y_val_encoded, y_pred, average='weighted', zero_division=0),\n",
    "        'Recall': recall_score(y_val_encoded, y_pred, average='weighted', zero_division=0),\n",
    "        'F1-Score': f1_score(y_val_encoded, y_pred, average='weighted', zero_division=0)\n",
    "    }\n",
    "    \n",
    "    print(f\"--- {name} ---\")\n",
    "    print(classification_report(y_val_encoded, y_pred, target_names=le.classes_, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deep Learning Models (LSTM & GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 100\n",
    "max_length = 50\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "X_val_sequences = tokenizer.texts_to_sequences(X_val)\n",
    "X_val_padded = pad_sequences(X_val_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "y_train_ohe = to_categorical(y_train_encoded)\n",
    "y_val_ohe = to_categorical(y_val_encoded)\n",
    "\n",
    "num_classes = len(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\Documents\\Projects\\Capstone-Project-ML2\\env\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "--- LSTM ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.00      0.00      0.00       378\n",
      "       false       0.20      1.00      0.33       452\n",
      "   half-true       0.00      0.00      0.00       472\n",
      " mostly-true       0.00      0.00      0.00       442\n",
      "  pants-fire       0.00      0.00      0.00       191\n",
      "        true       0.00      0.00      0.00       369\n",
      "\n",
      "    accuracy                           0.20      2304\n",
      "   macro avg       0.03      0.17      0.05      2304\n",
      "weighted avg       0.04      0.20      0.06      2304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    LSTM(128),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history_lstm = model_lstm.fit(\n",
    "    X_train_padded, y_train_ohe,\n",
    "    epochs=20,\n",
    "    validation_data=(X_val_padded, y_val_ohe),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "y_pred_proba_lstm = model_lstm.predict(X_val_padded)\n",
    "y_pred_lstm = np.argmax(y_pred_proba_lstm, axis=1)\n",
    "\n",
    "results_dl_lstm = {\n",
    "    'Accuracy': accuracy_score(y_val_encoded, y_pred_lstm),\n",
    "    'Precision': precision_score(y_val_encoded, y_pred_lstm, average='weighted', zero_division=0),\n",
    "    'Recall': recall_score(y_val_encoded, y_pred_lstm, average='weighted', zero_division=0),\n",
    "    'F1-Score': f1_score(y_val_encoded, y_pred_lstm, average='weighted', zero_division=0)\n",
    "}\n",
    "results_ml['LSTM'] = results_dl_lstm\n",
    "\n",
    "print(\"--- LSTM ---\")\n",
    "print(classification_report(y_val_encoded, y_pred_lstm, target_names=le.classes_, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\Documents\\Projects\\Capstone-Project-ML2\\env\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step\n",
      "--- GRU ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.00      0.00      0.00       378\n",
      "       false       0.00      0.00      0.00       452\n",
      "   half-true       0.20      1.00      0.34       472\n",
      " mostly-true       0.00      0.00      0.00       442\n",
      "  pants-fire       0.00      0.00      0.00       191\n",
      "        true       0.00      0.00      0.00       369\n",
      "\n",
      "    accuracy                           0.20      2304\n",
      "   macro avg       0.03      0.17      0.06      2304\n",
      "weighted avg       0.04      0.20      0.07      2304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_gru = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    GRU(128),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model_gru.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history_gru = model_gru.fit(\n",
    "    X_train_padded, y_train_ohe,\n",
    "    epochs=20,\n",
    "    validation_data=(X_val_padded, y_val_ohe),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "y_pred_proba_gru = model_gru.predict(X_val_padded)\n",
    "y_pred_gru = np.argmax(y_pred_proba_gru, axis=1)\n",
    "\n",
    "results_dl_gru = {\n",
    "    'Accuracy': accuracy_score(y_val_encoded, y_pred_gru),\n",
    "    'Precision': precision_score(y_val_encoded, y_pred_gru, average='weighted', zero_division=0),\n",
    "    'Recall': recall_score(y_val_encoded, y_pred_gru, average='weighted', zero_division=0),\n",
    "    'F1-Score': f1_score(y_val_encoded, y_pred_gru, average='weighted', zero_division=0)\n",
    "}\n",
    "results_ml['GRU'] = results_dl_gru\n",
    "\n",
    "print(\"--- GRU ---\")\n",
    "print(classification_report(y_val_encoded, y_pred_gru, target_names=le.classes_, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Final Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Comparison\n",
      "\n",
      " Accuracy Precision Recall F1-Score\n",
      "Logistic Regression 0.2478 0.2535 0.2478 0.2389\n",
      "Naive Bayes 0.2396 0.2531 0.2396 0.2184\n",
      "Linear SVM 0.2378 0.2365 0.2378 0.2367\n",
      "LSTM 0.1957 0.0385 0.1957 0.0643\n",
      "GRU 0.2049 0.0420 0.2049 0.0697\n",
      "\n",
      "\n",
      "The best performing model based on F1-Score is: Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame.from_dict(results_ml, orient='index')\n",
    "df_results_styled = df_results.style.format({ \n",
    "    'Accuracy': \"{:.4f}\", \n",
    "    'Precision': \"{:.4f}\", \n",
    "    'Recall': \"{:.4f}\", \n",
    "    'F1-Score': \"{:.4f}\" \n",
    "})\n",
    "print(\"Model Performance Comparison\\n\")\n",
    "print(df_results_styled.to_string())\n",
    "\n",
    "best_model_name = df_results['F1-Score'].idxmax()\n",
    "print(f\"\\nThe best performing model based on F1-Score is: {best_model_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "metadata": {
   "language_info": {
    "codemirror_mode": {
     "name": "ipython",
     "version": 3
    },
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": "3.10.12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
